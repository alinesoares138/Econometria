# Econometria

A **regressÃ£o linear** Ã© um mÃ©todo estatÃ­stico para modelar a relaÃ§Ã£o entre uma variÃ¡vel dependente \( Y \) e uma ou mais variÃ¡veis independentes \( X \). 
Ela busca ajustar uma equaÃ§Ã£o da forma:  

\[
Y = Î²0 + Î²1 X + Îµ
\]

Onde Î²0 Ã© o ponto onde a linha da regressÃ£o cruza o eixo Y (intercepto), Î²1 diz o quanto Y muda para cada unidade a mais em X (coeficiente angular), e Îµ representa a diferenÃ§a entre os valores previstos e os valores reais (erro). O objetivo Ã© encontrar os valores de Î²0 e Î²1 que fazem a linha se ajustar da melhor forma possÃ­vel aos dados.

## Aline, o que tudo isso significa?

Suponha que estamos modelando a relaÃ§Ã£o entre a temperatura (X, em Â°C) e a demanda por sorvete (Y, em unidades vendidas).
Se o modelo resultar em:

\[
Y = 50 + 10X + Îµ
\]

Isso significa que:

- Quando a temperatura Ã© 0Â°C, espera-se vender 50 sorvetes (ğ›½0 = 5). 
- Para cada aumento de 1Â°C, a venda de sorvetes aumenta em 10 unidades (ğ›½1 = 10).
- Se nÃ£o houvesse o intercepto, a equaÃ§Ã£o sempre passaria pela origem (X = 0, Y = 0), o que nem sempre faz sentido. Imagine um caso onde a temperatura Ã© 0Â°C, mas ainda hÃ¡ vendas de sorvete. O intercepto captura essa realidade.

```
df <- data.frame(
y <- c(360, 440, 550, 630, 700),
x <- c(100,200,300,400,500)
)
modelo <- lm(y ~ x, data = df)
summary(modelo)

--Resultado:

Call:
lm(formula = y ~ x, data = df)

Residuals:
  1   2   3   4   5 
 -2  -9  14   7 -10 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 275.00000   12.55654   21.90 0.000208 ***
x             0.87000    0.03786   22.98 0.000181 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 11.97 on 3 degrees of freedom
Multiple R-squared:  0.9944,	Adjusted R-squared:  0.9925 
F-statistic: 528.1 on 1 and 3 DF,  p-value: 0.0001805

coef(modelo)
(Intercept)           x 
     275.00        0.87

> b0
[1] 275
> b1
[1] 0.87

```

O coeficiente de determinaÃ§Ã£o, conhecido como RÂ², mede a proporÃ§Ã£o da variaÃ§Ã£o da variÃ¡vel dependente (Y) que Ã© explicada pelo modelo de regressÃ£o. Ou seja, o quanto o modelo de regressÃ£o consegue explicar os valores de Y. Ele varia entre 0 e 1, onde:
- Se RÂ² = 1 â†’ O modelo explica 100% dos dados, ou seja, os pontos caem exatamente na reta.
- Se RÂ² = 0 â†’ O modelo nÃ£o consegue explicar nada, ou seja, a reta nÃ£o faz sentido para os dados.

\[
RÂ² = 1 - (erro do modelo / variaÃ§Ã£o total dos dados)â€‹
\]

```
summary(modelo)$r.squared

-- Resultado:
[1] 0.994351

Ou, manualmente:
y_pred <- predict(modelo)
SQT <- sum((df$y - mean(df$y))^2)  # VariaÃ§Ã£o total de Y
SQR <- sum((df$y - y_pred)^2)  # Erro do modelo

R2 <- 1 - (SQR / SQT)  
R2

-- Resultado:
[1] 0.994351

```
